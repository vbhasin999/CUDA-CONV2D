{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "5dhX0AmhFvtD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvzUXqK_wAkB"
      },
      "outputs": [],
      "source": [
        "!pip install pybind11\n",
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get GPU Info"
      ],
      "metadata": {
        "id": "2Vsg0J1dFx92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "cuda.init()\n",
        "\n",
        "# Get the first CUDA device\n",
        "device = cuda.Device(0)\n",
        "\n",
        "print(\"Name:\", device.name())\n",
        "print(\"Compute capability:\", device.compute_capability())\n",
        "print(\"Total global memory (Gigabytes):\", device.total_memory() / 1024**3)\n",
        "print(\"Shared memory per block (Kilobytes):\", device.get_attribute(cuda.device_attribute.MAX_SHARED_MEMORY_PER_BLOCK) / 1024)\n",
        "print(\"Max threads per block:\", device.get_attribute(cuda.device_attribute.MAX_THREADS_PER_BLOCK))\n",
        "print(\"Max block dimensions:\", device.get_attribute(cuda.device_attribute.MAX_BLOCK_DIM_X),\n",
        "      device.get_attribute(cuda.device_attribute.MAX_BLOCK_DIM_Y),\n",
        "      device.get_attribute(cuda.device_attribute.MAX_BLOCK_DIM_Z))\n",
        "print(\"Max grid dimensions:\", device.get_attribute(cuda.device_attribute.MAX_GRID_DIM_X),\n",
        "      device.get_attribute(cuda.device_attribute.MAX_GRID_DIM_Y),\n",
        "      device.get_attribute(cuda.device_attribute.MAX_GRID_DIM_Z))"
      ],
      "metadata": {
        "id": "-e-FIwS-FvGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the repo and build"
      ],
      "metadata": {
        "id": "y1fdh2UxF03F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vbhasin999/CUDA-CONV2D"
      ],
      "metadata": {
        "id": "VdxSg_uvwGXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CUDA-CONV2D/conv2d\n",
        "!bash -x clean.sh\n",
        "!bash -x ./build.sh"
      ],
      "metadata": {
        "id": "zv9GsFTSdMmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with desired configuration\n",
        "Test.py runs the naive, kernel parallel, in channel parallel, and cpp baseline. Calculates execution times, speedups, and correctness checks\n"
      ],
      "metadata": {
        "id": "AfJ1wFFqGNx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 test.py --Cin 3 --H 512 --W 512 --Cout 16 --K 8"
      ],
      "metadata": {
        "id": "usMyIzCWb7Wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}